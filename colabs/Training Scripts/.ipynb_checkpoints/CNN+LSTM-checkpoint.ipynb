{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "753f1710-04a3-487b-93f7-ca580d8e8c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, LSTM, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f419d7cb-e814-4f20-af4f-e8cb3ae4a0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder paths\n",
    "folders = {\n",
    "    \"Abnormal Heartbeat\": r\"D:\\FYP\\Cadivas CNN\\preprocessed_1d\\AHB\",\n",
    "    \"Myocardial Infarction\": r\"D:\\FYP\\Cadivas CNN\\preprocessed_1d\\MI\",\n",
    "    \"Normal\": r\"D:\\FYP\\Cadivas CNN\\preprocessed_1d\\NORMAL\",\n",
    "    \"History of MI\": r\"D:\\FYP\\Cadivas CNN\\preprocessed_1d\\PM\"\n",
    "}\n",
    "\n",
    "all_data = []\n",
    "for label, folder in folders.items():\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(os.path.join(folder, file))\n",
    "            df['Class'] = label\n",
    "            all_data.append(df)\n",
    "\n",
    "# Combine all data\n",
    "data = pd.concat(all_data, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3a1fb5e-4cf4-4312-a12e-f92a33d60e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features (first 255 columns)\n",
    "X = data.iloc[:, :255].values  \n",
    "y = data['Class'].values\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "y_onehot = to_categorical(y_encoded)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d76864ac-21ac-47ec-a606-a9641156294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_onehot, test_size=0.2, random_state=42, stratify=y_onehot\n",
    ")\n",
    "\n",
    "# Reshape for CNN+LSTM (samples, timesteps, features=1)\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e011433f-8817-4ba0-b461-1c65bdabbc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 0.9957081545064378, 1: 1.3488372093023255, 2: 0.9707112970711297, 3: 0.8169014084507042}\n"
     ]
    }
   ],
   "source": [
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_encoded),\n",
    "    y=y_encoded\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "print(\"Class Weights:\", class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f9664b4-f478-47e5-9c1b-eec6e6870cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_5 (Conv1D)           (None, 255, 64)           384       \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 255, 64)          256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_5 (MaxPooling  (None, 127, 64)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " conv1d_6 (Conv1D)           (None, 127, 128)          41088     \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 127, 128)         512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " max_pooling1d_6 (MaxPooling  (None, 63, 128)          0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 256)               16640     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 4)                 1028      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,316\n",
      "Trainable params: 108,932\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "\n",
    "    Conv1D(64, kernel_size=5, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(128, kernel_size=5, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    LSTM(64, return_sequences=False),\n",
    "\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c51fbe4d-802c-4ff7-9244-e0a0f444edf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dedfb79b-ef4b-454f-b559-27dbe2c2c2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "151/151 [==============================] - 13s 68ms/step - loss: 1.3429 - accuracy: 0.3421 - val_loss: 1.4125 - val_accuracy: 0.2706 - lr: 0.0010\n",
      "Epoch 2/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 1.2424 - accuracy: 0.4338 - val_loss: 1.3571 - val_accuracy: 0.3336 - lr: 0.0010\n",
      "Epoch 3/120\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 1.1258 - accuracy: 0.5109 - val_loss: 1.2229 - val_accuracy: 0.4588 - lr: 0.0010\n",
      "Epoch 4/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 1.0019 - accuracy: 0.5808 - val_loss: 1.0229 - val_accuracy: 0.5640 - lr: 0.0010\n",
      "Epoch 5/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.9130 - accuracy: 0.6279 - val_loss: 0.8825 - val_accuracy: 0.6386 - lr: 0.0010\n",
      "Epoch 6/120\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.8225 - accuracy: 0.6726 - val_loss: 0.8274 - val_accuracy: 0.6755 - lr: 0.0010\n",
      "Epoch 7/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.7620 - accuracy: 0.6903 - val_loss: 0.7910 - val_accuracy: 0.6635 - lr: 0.0010\n",
      "Epoch 8/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.6930 - accuracy: 0.7252 - val_loss: 0.6743 - val_accuracy: 0.7290 - lr: 0.0010\n",
      "Epoch 9/120\n",
      "151/151 [==============================] - 10s 64ms/step - loss: 0.6296 - accuracy: 0.7431 - val_loss: 0.7029 - val_accuracy: 0.7004 - lr: 0.0010\n",
      "Epoch 10/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.6050 - accuracy: 0.7586 - val_loss: 0.6013 - val_accuracy: 0.7567 - lr: 0.0010\n",
      "Epoch 11/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.5488 - accuracy: 0.7817 - val_loss: 0.6377 - val_accuracy: 0.7414 - lr: 0.0010\n",
      "Epoch 12/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.5194 - accuracy: 0.7959 - val_loss: 0.6302 - val_accuracy: 0.7451 - lr: 0.0010\n",
      "Epoch 13/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.4762 - accuracy: 0.8154 - val_loss: 0.5861 - val_accuracy: 0.7663 - lr: 0.0010\n",
      "Epoch 14/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.4528 - accuracy: 0.8237 - val_loss: 0.5069 - val_accuracy: 0.7953 - lr: 0.0010\n",
      "Epoch 15/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.4352 - accuracy: 0.8305 - val_loss: 0.5406 - val_accuracy: 0.7795 - lr: 0.0010\n",
      "Epoch 16/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.4148 - accuracy: 0.8389 - val_loss: 0.5108 - val_accuracy: 0.8044 - lr: 0.0010\n",
      "Epoch 17/120\n",
      "151/151 [==============================] - 10s 65ms/step - loss: 0.3627 - accuracy: 0.8580 - val_loss: 0.4976 - val_accuracy: 0.8106 - lr: 0.0010\n",
      "Epoch 18/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.3666 - accuracy: 0.8580 - val_loss: 0.5005 - val_accuracy: 0.8210 - lr: 0.0010\n",
      "Epoch 19/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.3181 - accuracy: 0.8765 - val_loss: 0.4702 - val_accuracy: 0.8297 - lr: 0.0010\n",
      "Epoch 20/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2945 - accuracy: 0.8892 - val_loss: 0.4411 - val_accuracy: 0.8305 - lr: 0.0010\n",
      "Epoch 21/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2829 - accuracy: 0.8903 - val_loss: 0.4336 - val_accuracy: 0.8363 - lr: 0.0010\n",
      "Epoch 22/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2676 - accuracy: 0.8995 - val_loss: 0.4563 - val_accuracy: 0.8342 - lr: 0.0010\n",
      "Epoch 23/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2497 - accuracy: 0.9049 - val_loss: 0.5142 - val_accuracy: 0.8189 - lr: 0.0010\n",
      "Epoch 24/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.2525 - accuracy: 0.9021 - val_loss: 0.4292 - val_accuracy: 0.8537 - lr: 0.0010\n",
      "Epoch 25/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.2371 - accuracy: 0.9105 - val_loss: 0.4819 - val_accuracy: 0.8471 - lr: 0.0010\n",
      "Epoch 26/120\n",
      "151/151 [==============================] - 10s 69ms/step - loss: 0.2204 - accuracy: 0.9199 - val_loss: 0.3768 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 27/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.2048 - accuracy: 0.9220 - val_loss: 0.4320 - val_accuracy: 0.8591 - lr: 0.0010\n",
      "Epoch 28/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1919 - accuracy: 0.9299 - val_loss: 0.4013 - val_accuracy: 0.8637 - lr: 0.0010\n",
      "Epoch 29/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.1715 - accuracy: 0.9381 - val_loss: 0.4515 - val_accuracy: 0.8521 - lr: 0.0010\n",
      "Epoch 30/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.1790 - accuracy: 0.9323 - val_loss: 0.3989 - val_accuracy: 0.8827 - lr: 0.0010\n",
      "Epoch 31/120\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.1488 - accuracy: 0.9439\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.1488 - accuracy: 0.9439 - val_loss: 0.3833 - val_accuracy: 0.8848 - lr: 0.0010\n",
      "Epoch 32/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.1034 - accuracy: 0.9627 - val_loss: 0.3508 - val_accuracy: 0.8989 - lr: 5.0000e-04\n",
      "Epoch 33/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0847 - accuracy: 0.9702 - val_loss: 0.3780 - val_accuracy: 0.9097 - lr: 5.0000e-04\n",
      "Epoch 34/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0839 - accuracy: 0.9702 - val_loss: 0.3543 - val_accuracy: 0.9121 - lr: 5.0000e-04\n",
      "Epoch 35/120\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0810 - accuracy: 0.9717 - val_loss: 0.4029 - val_accuracy: 0.9047 - lr: 5.0000e-04\n",
      "Epoch 36/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0807 - accuracy: 0.9687 - val_loss: 0.4083 - val_accuracy: 0.9022 - lr: 5.0000e-04\n",
      "Epoch 37/120\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.0701 - accuracy: 0.9753\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0701 - accuracy: 0.9753 - val_loss: 0.3816 - val_accuracy: 0.9113 - lr: 5.0000e-04\n",
      "Epoch 38/120\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0565 - accuracy: 0.9809 - val_loss: 0.3848 - val_accuracy: 0.9167 - lr: 2.5000e-04\n",
      "Epoch 39/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0483 - accuracy: 0.9837 - val_loss: 0.3604 - val_accuracy: 0.9175 - lr: 2.5000e-04\n",
      "Epoch 40/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0479 - accuracy: 0.9837 - val_loss: 0.3503 - val_accuracy: 0.9171 - lr: 2.5000e-04\n",
      "Epoch 41/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0452 - accuracy: 0.9854 - val_loss: 0.3526 - val_accuracy: 0.9287 - lr: 2.5000e-04\n",
      "Epoch 42/120\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0441 - accuracy: 0.9850 - val_loss: 0.3755 - val_accuracy: 0.9250 - lr: 2.5000e-04\n",
      "Epoch 43/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 0.3704 - val_accuracy: 0.9213 - lr: 2.5000e-04\n",
      "Epoch 44/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0413 - accuracy: 0.9869 - val_loss: 0.3697 - val_accuracy: 0.9225 - lr: 2.5000e-04\n",
      "Epoch 45/120\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.0399 - accuracy: 0.9880\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "151/151 [==============================] - 10s 66ms/step - loss: 0.0399 - accuracy: 0.9880 - val_loss: 0.3812 - val_accuracy: 0.9275 - lr: 2.5000e-04\n",
      "Epoch 46/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 0.3879 - val_accuracy: 0.9271 - lr: 1.2500e-04\n",
      "Epoch 47/120\n",
      "151/151 [==============================] - 10s 68ms/step - loss: 0.0322 - accuracy: 0.9908 - val_loss: 0.3895 - val_accuracy: 0.9295 - lr: 1.2500e-04\n",
      "Epoch 48/120\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 0.3859 - val_accuracy: 0.9271 - lr: 1.2500e-04\n",
      "Epoch 49/120\n",
      "151/151 [==============================] - 10s 69ms/step - loss: 0.0287 - accuracy: 0.9916 - val_loss: 0.4144 - val_accuracy: 0.9262 - lr: 1.2500e-04\n",
      "Epoch 50/120\n",
      "151/151 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9933\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "151/151 [==============================] - 10s 67ms/step - loss: 0.0266 - accuracy: 0.9933 - val_loss: 0.4001 - val_accuracy: 0.9295 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=120,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler, early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf65c7e6-8449-4a2a-a87e-1c02691725a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76/76 [==============================] - 1s 10ms/step\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   Abnormal Heartbeat       0.94      0.83      0.88       606\n",
      "        History of MI       0.80      0.90      0.85       447\n",
      "Myocardial Infarction       0.97      1.00      0.99       621\n",
      "               Normal       0.93      0.93      0.93       739\n",
      "\n",
      "             accuracy                           0.92      2413\n",
      "            macro avg       0.91      0.91      0.91      2413\n",
      "         weighted avg       0.92      0.92      0.92      2413\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[504  64  10  28]\n",
      " [ 17 402   2  26]\n",
      " [  0   0 621   0]\n",
      " [ 14  35   4 686]]\n",
      "\n",
      "Final Test Accuracy: 91.71%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Predictions\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "y_pred_labels = np.argmax(y_pred_probs, axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test_labels, y_pred_labels, target_names=label_encoder.classes_))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test_labels, y_pred_labels)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "print(\"\\nFinal Test Accuracy: {:.2f}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4c7b3ae-d52c-4ce3-9345-9d4f945ba536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder(cnn+lstm).pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save(\"CNN+LSTM(91).h5\")\n",
    "import joblib\n",
    "joblib.dump(label_encoder, \"label_encoder(cnn+lstm).pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12197d33-0642-4e52-883a-8ab9494c1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34e1504f-cde5-4882-9706-b2cd761901df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input, Bidirectional, LSTM\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4628f3b0-a47c-402e-8873-db8695a937b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X, y already prepared (X: signals, y: labels)\n",
    "\n",
    "# Encode labels\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_onehot = tf.keras.utils.to_categorical(y_encoded)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_onehot, test_size=0.2, random_state=42, stratify=y_onehot\n",
    ")\n",
    "\n",
    "# Expand dims for Conv1D (samples, timesteps, channels)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "\n",
    "# Augmentation: add Gaussian noise\n",
    "def add_noise(X, noise_factor=0.01):\n",
    "    return X + noise_factor * np.random.normal(size=X.shape)\n",
    "\n",
    "X_train_noisy = add_noise(X_train)\n",
    "y_train_noisy = y_train.copy()\n",
    "\n",
    "# Concatenate original + augmented\n",
    "X_train_aug = np.concatenate([X_train, X_train_noisy])\n",
    "y_train_aug = np.concatenate([y_train, y_train_noisy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ba85a5d-b9cb-46d4-97f0-4cc8b8e43c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1], 1)),\n",
    "\n",
    "    # CNN Feature Extractor\n",
    "    Conv1D(128, kernel_size=5, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    Conv1D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "    BatchNormalization(),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "\n",
    "    # BiLSTM for temporal dependencies\n",
    "    Bidirectional(LSTM(128, return_sequences=False)),\n",
    "\n",
    "    # Fully connected\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(y_onehot.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48f2d69-373e-45a6-8977-9078bc9808db",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=8, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_aug, y_train_aug,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6",
   "language": "python",
   "name": "py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
